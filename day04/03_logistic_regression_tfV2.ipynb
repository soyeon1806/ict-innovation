{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y의 데이터 값\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "x_data = np.array([x_row[0] for x_row in data], dtype = np.float64)\n",
    "y_data = np.array([x_row[1] for x_row in data], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a와 b의 값을 임의로 정함\n",
    "a = tf.Variable(tf.random.normal([1], dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random.normal([1], dtype = tf.float64, seed= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 함수 (시그모이드 함수)\n",
    "def hypothesis(a, b):\n",
    "    return 1 / (1 + tf.math.exp(-(a * x_data + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def cost(a, b):\n",
    "    return -tf.reduce_mean(y_data * tf.math.log(hypothesis(a, b)) + (1 - y_data) * tf.math.log(1 - hypothesis(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 함수\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Cost: 4.198056559821054, a: [2.45719506], b: [-0.03358081]\n",
      "Step: 6000, Cost: 0.015171303238125116, a: [2.92268135], b: [-20.30933691]\n",
      "Step: 12000, Cost: 0.008063672443297264, a: [3.56459439], b: [-24.8069916]\n",
      "Step: 18000, Cost: 0.005471899246001151, a: [3.95630493], b: [-27.55039467]\n",
      "Step: 24000, Cost: 0.0041353991771165815, a: [4.23846392], b: [-29.52621989]\n",
      "Step: 30000, Cost: 0.0033214864800667145, a: [4.45894767], b: [-31.07003192]\n",
      "Step: 36000, Cost: 0.002774288478874987, a: [4.63985768], b: [-32.33668483]\n",
      "Step: 42000, Cost: 0.0023813726361869097, a: [4.79322008], b: [-33.41042306]\n",
      "Step: 48000, Cost: 0.0020856521469861072, a: [4.92630368], b: [-34.34215902]\n",
      "Step: 54000, Cost: 0.001855084711645364, a: [5.04383702], b: [-35.16500937]\n",
      "Step: 60000, Cost: 0.0016703048965725296, a: [5.14906839], b: [-35.90172237]\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for i in range(60001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_cost = cost(a, b)\n",
    "    grads = tape.gradient(current_cost, [a, b])\n",
    "    opt.apply_gradients(zip(grads, [a, b]))\n",
    "    if i % 6000 == 0:\n",
    "        print(f\"Step: {i}, Cost: {current_cost.numpy()}, a: {a.numpy()}, b: {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 결과 - a: [5.14906839], b: [-35.90172237]\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "print(f\"최종 결과 - a: {a.numpy()}, b: {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.88260468e-05]\n",
      "0.0000388260468402570663084411028975750924\n",
      "[0.53537987]\n",
      "0.5353798705782886191428815436665900051594\n",
      "[1.]\n",
      "0.9999999999999666933092612453037872910500\n"
     ]
    }
   ],
   "source": [
    "# 다른 값 확인해보기\n",
    "new_x_data = 5\n",
    "y_test = 1 / (1 + np.e** - (a * new_x_data + b))\n",
    "print(y_test.numpy())\n",
    "print(\"%.40f\" % float(y_test.numpy()))\n",
    "\n",
    "new_x_data = 7\n",
    "y_test = 1 / (1 + np.e** - (a * new_x_data + b))\n",
    "print(y_test.numpy())\n",
    "print(\"%.40f\" % float(y_test.numpy()))\n",
    "\n",
    "new_x_data = 13\n",
    "y_test = 1 / (1 + np.e** - (a * new_x_data + b))\n",
    "print(y_test.numpy())\n",
    "print(\"%.40f\" % float(y_test.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
