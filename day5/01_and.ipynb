{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [0], [0], [1]], dtype = np.float32)\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  0.6092484 w =  [[ 0.51382405]\n",
      " [-0.01113636]] b =  [-0.3761821]\n",
      "step =  100 cost =  0.5699783 w =  [[0.5096648]\n",
      " [0.0159659]] b =  [-0.5719159]\n",
      "step =  200 cost =  0.54266596 w =  [[0.5245024]\n",
      " [0.0595894]] b =  [-0.7303415]\n",
      "step =  300 cost =  0.5213796 w =  [[0.55162424]\n",
      " [0.11323525]] b =  [-0.86313283]\n",
      "step =  400 cost =  0.50340486 w =  [[0.5865577 ]\n",
      " [0.17270449]] b =  [-0.9780276]\n",
      "step =  500 cost =  0.48746505 w =  [[0.6263365 ]\n",
      " [0.23527718]] b =  [-1.0801799]\n",
      "step =  600 cost =  0.47293237 w =  [[0.6689883 ]\n",
      " [0.29918265]] b =  [-1.1730615]\n",
      "step =  700 cost =  0.45947784 w =  [[0.71319807]\n",
      " [0.36326885]] b =  [-1.2590401]\n",
      "step =  800 cost =  0.44691366 w =  [[0.7580907]\n",
      " [0.4267916]] b =  [-1.339749]\n",
      "step =  900 cost =  0.43512082 w =  [[0.8030871 ]\n",
      " [0.48927987]] b =  [-1.4163253]\n",
      "step =  1000 cost =  0.42401516 w =  [[0.84780836]\n",
      " [0.5504457 ]] b =  [-1.489572]\n",
      "step =  1100 cost =  0.41353145 w =  [[0.8920126]\n",
      " [0.6101245]] b =  [-1.5600628]\n",
      "step =  1200 cost =  0.40361595 w =  [[0.9355494 ]\n",
      " [0.66823465]] b =  [-1.6282094]\n",
      "step =  1300 cost =  0.39422214 w =  [[0.97833127]\n",
      " [0.72474974]] b =  [-1.6943176]\n",
      "step =  1400 cost =  0.38530877 w =  [[1.0203134 ]\n",
      " [0.77967936]] b =  [-1.7586156]\n",
      "step =  1500 cost =  0.37683922 w =  [[1.0614779]\n",
      " [0.8330563]] b =  [-1.8212776]\n",
      "step =  1600 cost =  0.3687803 w =  [[1.1018262 ]\n",
      " [0.88492715]] b =  [-1.8824412]\n",
      "step =  1700 cost =  0.36110193 w =  [[1.1413713]\n",
      " [0.9353476]] b =  [-1.9422151]\n",
      "step =  1800 cost =  0.35377675 w =  [[1.180132 ]\n",
      " [0.9843771]] b =  [-2.0006907]\n",
      "step =  1900 cost =  0.34677997 w =  [[1.2181333]\n",
      " [1.0320765]] b =  [-2.057944]\n",
      "step =  2000 cost =  0.34008902 w =  [[1.2554015]\n",
      " [1.0785068]] b =  [-2.1140394]\n",
      "step =  2100 cost =  0.33368307 w =  [[1.2919642]\n",
      " [1.12373  ]] b =  [-2.1690354]\n",
      "step =  2200 cost =  0.3275435 w =  [[1.327848 ]\n",
      " [1.1677984]] b =  [-2.2229826]\n",
      "step =  2300 cost =  0.32165292 w =  [[1.3630803]\n",
      " [1.2107698]] b =  [-2.2759273]\n",
      "step =  2400 cost =  0.31599542 w =  [[1.3976865]\n",
      " [1.2526959]] b =  [-2.327912]\n",
      "step =  2500 cost =  0.31055656 w =  [[1.431692 ]\n",
      " [1.2936263]] b =  [-2.3789766]\n",
      "step =  2600 cost =  0.30532297 w =  [[1.4651196]\n",
      " [1.3336079]] b =  [-2.429156]\n",
      "step =  2700 cost =  0.30028248 w =  [[1.4979916]\n",
      " [1.3726845]] b =  [-2.4784846]\n",
      "step =  2800 cost =  0.29542363 w =  [[1.5303295]\n",
      " [1.4108974]] b =  [-2.5269933]\n",
      "step =  2900 cost =  0.29073614 w =  [[1.5621529]\n",
      " [1.4482853]] b =  [-2.574713]\n",
      "step =  3000 cost =  0.28621024 w =  [[1.593481 ]\n",
      " [1.4848863]] b =  [-2.6216717]\n",
      "step =  3100 cost =  0.2818371 w =  [[1.6243311]\n",
      " [1.5207336]] b =  [-2.6678956]\n",
      "step =  3200 cost =  0.2776085 w =  [[1.65472  ]\n",
      " [1.5558604]] b =  [-2.7134094]\n",
      "step =  3300 cost =  0.2735167 w =  [[1.6846634]\n",
      " [1.5902967]] b =  [-2.7582371]\n",
      "step =  3400 cost =  0.26955473 w =  [[1.7141763]\n",
      " [1.6240718]] b =  [-2.802401]\n",
      "step =  3500 cost =  0.2657159 w =  [[1.7432729]\n",
      " [1.6572124]] b =  [-2.845923]\n",
      "step =  3600 cost =  0.26199397 w =  [[1.7719657]\n",
      " [1.6897446]] b =  [-2.8888233]\n",
      "step =  3700 cost =  0.25838345 w =  [[1.8002684]\n",
      " [1.721692 ]] b =  [-2.9311204]\n",
      "step =  3800 cost =  0.25487876 w =  [[1.8281925]\n",
      " [1.7530776]] b =  [-2.9728343]\n",
      "step =  3900 cost =  0.25147504 w =  [[1.8557492]\n",
      " [1.7839229]] b =  [-3.0139818]\n",
      "step =  4000 cost =  0.24816756 w =  [[1.8829492]\n",
      " [1.814248 ]] b =  [-3.05458]\n",
      "step =  4100 cost =  0.24495192 w =  [[1.9098032]\n",
      " [1.8440725]] b =  [-3.094644]\n",
      "step =  4200 cost =  0.24182414 w =  [[1.9363203]\n",
      " [1.8734143]] b =  [-3.1341898]\n",
      "step =  4300 cost =  0.23878023 w =  [[1.9625103]\n",
      " [1.9022906]] b =  [-3.173232]\n",
      "step =  4400 cost =  0.23581666 w =  [[1.9883819]\n",
      " [1.930718 ]] b =  [-3.2117841]\n",
      "step =  4500 cost =  0.23292997 w =  [[2.0139432]\n",
      " [1.9587117]] b =  [-3.24986]\n",
      "step =  4600 cost =  0.23011696 w =  [[2.0392036]\n",
      " [1.9862868]] b =  [-3.287473]\n",
      "step =  4700 cost =  0.22737464 w =  [[2.0641687]\n",
      " [2.0134563]] b =  [-3.324634]\n",
      "step =  4800 cost =  0.22470026 w =  [[2.0888472]\n",
      " [2.0402346]] b =  [-3.3613555]\n",
      "step =  4900 cost =  0.22209096 w =  [[2.1132457]\n",
      " [2.066634 ]] b =  [-3.397649]\n",
      "step =  5000 cost =  0.21954429 w =  [[2.137371 ]\n",
      " [2.0926661]] b =  [-3.4335246]\n",
      "step =  5100 cost =  0.21705788 w =  [[2.16123  ]\n",
      " [2.1183426]] b =  [-3.468994]\n",
      "step =  5200 cost =  0.21462929 w =  [[2.184829 ]\n",
      " [2.1436746]] b =  [-3.5040658]\n",
      "step =  5300 cost =  0.21225663 w =  [[2.2081733]\n",
      " [2.168672 ]] b =  [-3.5387495]\n",
      "step =  5400 cost =  0.20993766 w =  [[2.2312694]\n",
      " [2.1933453]] b =  [-3.573055]\n",
      "step =  5500 cost =  0.20767054 w =  [[2.2541223]\n",
      " [2.217703 ]] b =  [-3.6069913]\n",
      "step =  5600 cost =  0.2054534 w =  [[2.2767375]\n",
      " [2.2417552]] b =  [-3.6405663]\n",
      "step =  5700 cost =  0.20328447 w =  [[2.2991204]\n",
      " [2.2655098]] b =  [-3.6737888]\n",
      "step =  5800 cost =  0.2011621 w =  [[2.3212762]\n",
      " [2.2889757]] b =  [-3.7066658]\n",
      "step =  5900 cost =  0.19908474 w =  [[2.3432088]\n",
      " [2.3121607]] b =  [-3.7392066]\n",
      "step =  6000 cost =  0.19705084 w =  [[2.3649235]\n",
      " [2.3350718]] b =  [-3.7714174]\n",
      "step =  6100 cost =  0.19505896 w =  [[2.386425 ]\n",
      " [2.3577163]] b =  [-3.8033056]\n",
      "step =  6200 cost =  0.19310775 w =  [[2.4077172]\n",
      " [2.3801017]] b =  [-3.8348782]\n",
      "step =  6300 cost =  0.1911959 w =  [[2.4288046]\n",
      " [2.4022338]] b =  [-3.8661418]\n",
      "step =  6400 cost =  0.18932214 w =  [[2.4496908]\n",
      " [2.42412  ]] b =  [-3.8971035]\n",
      "step =  6500 cost =  0.18748528 w =  [[2.4703805]\n",
      " [2.445766 ]] b =  [-3.927768]\n",
      "step =  6600 cost =  0.18568417 w =  [[2.490877]\n",
      " [2.467178]] b =  [-3.9581423]\n",
      "step =  6700 cost =  0.18391779 w =  [[2.5111835]\n",
      " [2.4883614]] b =  [-3.988232]\n",
      "step =  6800 cost =  0.18218502 w =  [[2.5313044]\n",
      " [2.5093215]] b =  [-4.0180426]\n",
      "step =  6900 cost =  0.18048489 w =  [[2.5512433]\n",
      " [2.5300632]] b =  [-4.04758]\n",
      "step =  7000 cost =  0.17881641 w =  [[2.5710022]\n",
      " [2.5505922]] b =  [-4.076848]\n",
      "step =  7100 cost =  0.1771787 w =  [[2.590586]\n",
      " [2.570913]] b =  [-4.1058545]\n",
      "step =  7200 cost =  0.1755708 w =  [[2.6099968]\n",
      " [2.5910308]] b =  [-4.134601]\n",
      "step =  7300 cost =  0.17399202 w =  [[2.6292381]\n",
      " [2.6109495]] b =  [-4.1630945]\n",
      "step =  7400 cost =  0.17244142 w =  [[2.6483126]\n",
      " [2.6306736]] b =  [-4.19134]\n",
      "step =  7500 cost =  0.17091817 w =  [[2.6672235]\n",
      " [2.650208 ]] b =  [-4.2193413]\n",
      "step =  7600 cost =  0.16942164 w =  [[2.6859734]\n",
      " [2.6695557]] b =  [-4.2471027]\n",
      "step =  7700 cost =  0.16795102 w =  [[2.7045658]\n",
      " [2.6887212]] b =  [-4.274628]\n",
      "step =  7800 cost =  0.16650566 w =  [[2.723002 ]\n",
      " [2.7077084]] b =  [-4.301923]\n",
      "step =  7900 cost =  0.16508487 w =  [[2.7412863]\n",
      " [2.7265208]] b =  [-4.3289905]\n",
      "step =  8000 cost =  0.16368794 w =  [[2.7594197]\n",
      " [2.7451615]] b =  [-4.3558345]\n",
      "step =  8100 cost =  0.16231443 w =  [[2.7774055]\n",
      " [2.7636347]] b =  [-4.3824587]\n",
      "step =  8200 cost =  0.16096354 w =  [[2.7952461]\n",
      " [2.7819433]] b =  [-4.408868]\n",
      "step =  8300 cost =  0.15963483 w =  [[2.8129437]\n",
      " [2.8000906]] b =  [-4.4350634]\n",
      "step =  8400 cost =  0.1583277 w =  [[2.8305006]\n",
      " [2.8180797]] b =  [-4.4610505]\n",
      "step =  8500 cost =  0.15704158 w =  [[2.8479187]\n",
      " [2.8359134]] b =  [-4.4868336]\n",
      "step =  8600 cost =  0.15577596 w =  [[2.8652008]\n",
      " [2.8535948]] b =  [-4.5124135]\n",
      "step =  8700 cost =  0.15453035 w =  [[2.8823488]\n",
      " [2.8711262]] b =  [-4.5377946]\n",
      "step =  8800 cost =  0.15330432 w =  [[2.899364]\n",
      " [2.888511]] b =  [-4.5629807]\n",
      "step =  8900 cost =  0.15209731 w =  [[2.9162502]\n",
      " [2.905752 ]] b =  [-4.5879736]\n",
      "step =  9000 cost =  0.15090892 w =  [[2.9330075]\n",
      " [2.9228516]] b =  [-4.612778]\n",
      "step =  9100 cost =  0.14973864 w =  [[2.9496386]\n",
      " [2.9398122]] b =  [-4.6373963]\n",
      "step =  9200 cost =  0.14858615 w =  [[2.966146 ]\n",
      " [2.9566355]] b =  [-4.6618314]\n",
      "step =  9300 cost =  0.14745103 w =  [[2.9825308]\n",
      " [2.9733248]] b =  [-4.6860833]\n",
      "step =  9400 cost =  0.14633277 w =  [[2.9987948]\n",
      " [2.9898822]] b =  [-4.7101574]\n",
      "step =  9500 cost =  0.14523107 w =  [[3.01494]\n",
      " [3.00631]] b =  [-4.734058]\n",
      "step =  9600 cost =  0.14414556 w =  [[3.030968]\n",
      " [3.02261 ]] b =  [-4.7577834]\n",
      "step =  9700 cost =  0.1430759 w =  [[3.0468805]\n",
      " [3.0387847]] b =  [-4.7813396]\n",
      "step =  9800 cost =  0.14202164 w =  [[3.0626793]\n",
      " [3.0548365]] b =  [-4.804728]\n",
      "step =  9900 cost =  0.14098251 w =  [[3.078366 ]\n",
      " [3.0707667]] b =  [-4.827951]\n",
      "step =  10000 cost =  0.13995825 w =  [[3.0939415]\n",
      " [3.0865774]] b =  [-4.85101]\n",
      "\n",
      "Hypothesis:  [[0.00775979]\n",
      " [0.14623606]\n",
      " [0.14715788]\n",
      " [0.79075944]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n",
      "\n",
      "새로운 데이터 Hypothesis:  [[0.79075944]\n",
      " [0.14623606]\n",
      " [0.14715788]\n",
      " [0.00775979]] \n",
      "새로운 데이터 Prediction:  [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step = \", step, \"cost = \", sess.run(cost, feed_dict = {X: x_data, Y: y_data}), \"w = \", sess.run(W), \"b = \", sess.run(b))\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "    new_data = np.array([[1, 1], [0, 1], [1, 0], [0, 0]], dtype = np.float32)\n",
    "    new_prediction = sess.run(predicted, feed_dict = {X: new_data})\n",
    "    new_hypothesis = sess.run(hypothesis, feed_dict = {X: new_data})\n",
    "    print(\"\\n새로운 데이터 Hypothesis: \", new_hypothesis, \"\\n새로운 데이터 Prediction: \", new_prediction)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
