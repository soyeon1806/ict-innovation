{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  0.7506918 [[0.09460632]\n",
      " [0.7436818 ]]\n",
      "step =  100 cost =  0.68337435 [[0.24110152]\n",
      " [1.0895848 ]]\n",
      "step =  200 cost =  0.67865574 [[0.21775432]\n",
      " [1.1502262 ]]\n",
      "step =  300 cost =  0.67360294 [[0.19546448]\n",
      " [1.2278875 ]]\n",
      "step =  400 cost =  0.6678499 [[0.17668979]\n",
      " [1.3224194 ]]\n",
      "step =  500 cost =  0.66111046 [[0.1629246]\n",
      " [1.4326307]]\n",
      "step =  600 cost =  0.653188 [[0.15586142]\n",
      " [1.5574214 ]]\n",
      "step =  700 cost =  0.64402974 [[0.1574067]\n",
      " [1.6951017]]\n",
      "step =  800 cost =  0.63377154 [[0.16952379]\n",
      " [1.8429399 ]]\n",
      "step =  900 cost =  0.6227157 [[0.19393282]\n",
      " [1.9972038 ]]\n",
      "step =  1000 cost =  0.61122787 [[0.23179892]\n",
      " [2.15381   ]]\n",
      "step =  1100 cost =  0.5996264 [[0.2835736]\n",
      " [2.3092077]]\n",
      "step =  1200 cost =  0.5881289 [[0.34902695]\n",
      " [2.4609427 ]]\n",
      "step =  1300 cost =  0.5768613 [[0.42738208]\n",
      " [2.6077154 ]]\n",
      "step =  1400 cost =  0.5658902 [[0.5174528]\n",
      " [2.749091 ]]\n",
      "step =  1500 cost =  0.55524945 [[0.6177581]\n",
      " [2.8851488]]\n",
      "step =  1600 cost =  0.5449561 [[0.72662723]\n",
      " [3.0162046 ]]\n",
      "step =  1700 cost =  0.5350173 [[0.8423089]\n",
      " [3.1426485]]\n",
      "step =  1800 cost =  0.52543235 [[0.96307737]\n",
      " [3.2648568 ]]\n",
      "step =  1900 cost =  0.5161936 [[1.0873181]\n",
      " [3.3831863]]\n",
      "step =  2000 cost =  0.5072853 [[1.2135929]\n",
      " [3.4979682]]\n",
      "step =  2100 cost =  0.4986835 [[1.3406861]\n",
      " [3.6095083]]\n",
      "step =  2200 cost =  0.49035016 [[1.4676499]\n",
      " [3.7180667]]\n",
      "step =  2300 cost =  0.48222423 [[1.5938606]\n",
      " [3.8238208]]\n",
      "step =  2400 cost =  0.4742067 [[1.7190979]\n",
      " [3.9268053]]\n",
      "step =  2500 cost =  0.46613234 [[1.8436728]\n",
      " [4.026826 ]]\n",
      "step =  2600 cost =  0.45772496 [[1.968631 ]\n",
      " [4.1233244]]\n",
      "step =  2700 cost =  0.4485218 [[2.0960815]\n",
      " [4.2151694]]\n",
      "step =  2800 cost =  0.43777135 [[2.2296658]\n",
      " [4.300374 ]]\n",
      "step =  2900 cost =  0.42438564 [[2.374965 ]\n",
      " [4.3759913]]\n",
      "step =  3000 cost =  0.40724283 [[2.5390258]\n",
      " [4.4390063]]\n",
      "step =  3100 cost =  0.38611227 [[2.7276113]\n",
      " [4.4893556]]\n",
      "step =  3200 cost =  0.3623032 [[2.940767 ]\n",
      " [4.5327206]]\n",
      "step =  3300 cost =  0.3377367 [[3.1712742]\n",
      " [4.577613 ]]\n",
      "step =  3400 cost =  0.31373587 [[3.4084268]\n",
      " [4.62978  ]]\n",
      "step =  3500 cost =  0.29090893 [[3.6429513]\n",
      " [4.690915 ]]\n",
      "step =  3600 cost =  0.26950723 [[3.869015]\n",
      " [4.760415]]\n",
      "step =  3700 cost =  0.2496503 [[4.083753]\n",
      " [4.836878]]\n",
      "step =  3800 cost =  0.23139231 [[4.2861433]\n",
      " [4.9187546]]\n",
      "step =  3900 cost =  0.2147296 [[4.4761596]\n",
      " [5.0045853]]\n",
      "step =  4000 cost =  0.19960746 [[4.654277]\n",
      " [5.093072]]\n",
      "step =  4100 cost =  0.18593241 [[4.8212123]\n",
      " [5.18311  ]]\n",
      "step =  4200 cost =  0.17358957 [[4.9777875]\n",
      " [5.273785 ]]\n",
      "step =  4300 cost =  0.16245458 [[5.1248493]\n",
      " [5.364357 ]]\n",
      "step =  4400 cost =  0.15240374 [[5.2632213]\n",
      " [5.454255 ]]\n",
      "step =  4500 cost =  0.1433197 [[5.3936744]\n",
      " [5.5430393]]\n",
      "step =  4600 cost =  0.1350945 [[5.516923 ]\n",
      " [5.6303844]]\n",
      "step =  4700 cost =  0.12763095 [[5.6336117]\n",
      " [5.716059 ]]\n",
      "step =  4800 cost =  0.12084232 [[5.7443256]\n",
      " [5.7999034]]\n",
      "step =  4900 cost =  0.11465224 [[5.849586]\n",
      " [5.881816]]\n",
      "step =  5000 cost =  0.108993664 [[5.9498577]\n",
      " [5.9617386]]\n",
      "step =  5100 cost =  0.1038076 [[6.0455604]\n",
      " [6.039649 ]]\n",
      "step =  5200 cost =  0.09904271 [[6.137066]\n",
      " [6.115552]]\n",
      "step =  5300 cost =  0.09465421 [[6.2247014]\n",
      " [6.1894655]]\n",
      "step =  5400 cost =  0.090602614 [[6.308766]\n",
      " [6.261426]]\n",
      "step =  5500 cost =  0.08685336 [[6.389524 ]\n",
      " [6.3314795]]\n",
      "step =  5600 cost =  0.08337623 [[6.467217]\n",
      " [6.399679]]\n",
      "step =  5700 cost =  0.08014451 [[6.542059 ]\n",
      " [6.4660797]]\n",
      "step =  5800 cost =  0.07713465 [[6.6142454]\n",
      " [6.530742 ]]\n",
      "step =  5900 cost =  0.07432603 [[6.6839485]\n",
      " [6.593727 ]]\n",
      "step =  6000 cost =  0.07170017 [[6.751333 ]\n",
      " [6.6550946]]\n",
      "step =  6100 cost =  0.06924069 [[6.8165426]\n",
      " [6.714906 ]]\n",
      "step =  6200 cost =  0.06693314 [[6.8797073]\n",
      " [6.7732205]]\n",
      "step =  6300 cost =  0.06476455 [[6.940948]\n",
      " [6.830095]]\n",
      "step =  6400 cost =  0.06272322 [[7.0003767]\n",
      " [6.8855863]]\n",
      "step =  6500 cost =  0.060798924 [[7.0580945]\n",
      " [6.939746 ]]\n",
      "step =  6600 cost =  0.05898218 [[7.114197]\n",
      " [6.992627]]\n",
      "step =  6700 cost =  0.057264708 [[7.168766]\n",
      " [7.044282]]\n",
      "step =  6800 cost =  0.055638827 [[7.221884 ]\n",
      " [7.0947547]]\n",
      "step =  6900 cost =  0.05409775 [[7.2736244]\n",
      " [7.1440916]]\n",
      "step =  7000 cost =  0.052635238 [[7.324054]\n",
      " [7.192339]]\n",
      "step =  7100 cost =  0.051245686 [[7.373236]\n",
      " [7.239536]]\n",
      "step =  7200 cost =  0.049923882 [[7.4212327]\n",
      " [7.2857227]]\n",
      "step =  7300 cost =  0.04866518 [[7.468096 ]\n",
      " [7.3309402]]\n",
      "step =  7400 cost =  0.047465403 [[7.5138783]\n",
      " [7.375219 ]]\n",
      "step =  7500 cost =  0.04632055 [[7.558627]\n",
      " [7.418596]]\n",
      "step =  7600 cost =  0.045227133 [[7.602389]\n",
      " [7.461104]]\n",
      "step =  7700 cost =  0.044181842 [[7.6452026]\n",
      " [7.5027742]]\n",
      "step =  7800 cost =  0.043181613 [[7.687109]\n",
      " [7.543639]]\n",
      "step =  7900 cost =  0.042223744 [[7.7281437]\n",
      " [7.583721 ]]\n",
      "step =  8000 cost =  0.04130563 [[7.768345]\n",
      " [7.623051]]\n",
      "step =  8100 cost =  0.040424973 [[7.807742]\n",
      " [7.661655]]\n",
      "step =  8200 cost =  0.03957955 [[7.8463683]\n",
      " [7.699556 ]]\n",
      "step =  8300 cost =  0.038767334 [[7.884252]\n",
      " [7.736778]]\n",
      "step =  8400 cost =  0.037986524 [[7.921421 ]\n",
      " [7.7733436]]\n",
      "step =  8500 cost =  0.037235297 [[7.9579005]\n",
      " [7.809274 ]]\n",
      "step =  8600 cost =  0.036512077 [[7.9937162]\n",
      " [7.844591 ]]\n",
      "step =  8700 cost =  0.03581538 [[8.0288925]\n",
      " [7.879312 ]]\n",
      "step =  8800 cost =  0.035143815 [[8.063447]\n",
      " [7.913456]]\n",
      "step =  8900 cost =  0.03449613 [[8.097405]\n",
      " [7.947041]]\n",
      "step =  9000 cost =  0.033870943 [[8.130787]\n",
      " [7.980084]]\n",
      "step =  9100 cost =  0.03326726 [[8.1636095]\n",
      " [8.012601 ]]\n",
      "step =  9200 cost =  0.03268402 [[8.195891]\n",
      " [8.044607]]\n",
      "step =  9300 cost =  0.032120164 [[8.227651]\n",
      " [8.07612 ]]\n",
      "step =  9400 cost =  0.031574767 [[8.258903]\n",
      " [8.107154]]\n",
      "step =  9500 cost =  0.031046983 [[8.289664]\n",
      " [8.13772 ]]\n",
      "step =  9600 cost =  0.03053601 [[8.31995 ]\n",
      " [8.167835]]\n",
      "step =  9700 cost =  0.030041032 [[8.349776]\n",
      " [8.197506]]\n",
      "step =  9800 cost =  0.029561356 [[8.379151]\n",
      " [8.226752]]\n",
      "step =  9900 cost =  0.029096287 [[8.408092]\n",
      " [8.255578]]\n",
      "step =  10000 cost =  0.028645143 [[8.436609]\n",
      " [8.284001]]\n",
      "\n",
      "Hypothesis:  [[0.03055455]\n",
      " [0.9761209 ]\n",
      " [0.9759721 ]\n",
      " [0.03445193]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step = \", step, \"cost = \", sess.run(cost, feed_dict = {X: x_data, Y: y_data}),sess.run(W2))\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
