{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x_train = [x_row[0] for x_row in data]\n",
    "y_train = [y_row[1] for y_row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random.uniform([1], 0, 100, dtype = tf.float64, seed = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(w, b):\n",
    "    return x_train * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunc():\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w, b) - y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(w, b):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w, b) - y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31.108581142537346, [7.5236665], [78.22530992]\n",
      "100 2.907630589791604, [2.46033278], [78.04320254]\n",
      "200 2.8896758579816764, [2.39146795], [78.4541584]\n",
      "300 2.8837958465269438, [2.35207199], [78.68925662]\n",
      "400 2.8818862811358215, [2.32962379], [78.82321789]\n",
      "500 2.881267844754225, [2.31684923], [78.89945103]\n",
      "600 2.881067735644112, [2.3095827], [78.94281455]\n",
      "700 2.881003004574224, [2.30544986], [78.96747755]\n",
      "800 2.880982067404832, [2.30309942], [78.98150401]\n",
      "900 2.8809752955136854, [2.30176268], [78.98948108]\n",
      "1000 2.8809731052434207, [2.30100246], [78.99401776]\n",
      "1100 2.8809723968344256, [2.30057011], [78.99659782]\n",
      "1200 2.880972167710743, [2.30032423], [78.99806514]\n",
      "1300 2.8809720936043375, [2.30018439], [78.99889962]\n",
      "1400 2.8809720696358028, [2.30010487], [78.9993742]\n",
      "1500 2.880972061883564, [2.30005964], [78.9996441]\n",
      "1600 2.880972059376226, [2.30003392], [78.9997976]\n",
      "1700 2.8809720585652703, [2.30001929], [78.99988489]\n",
      "1800 2.8809720583029756, [2.30001097], [78.99993454]\n",
      "1900 2.880972058218145, [2.30000624], [78.99996277]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost(w, b)\n",
    "    gradients = tape.gradient(loss, [w, b])\n",
    "    opt.apply_gradients(zip(gradients, [w, b]))\n",
    "    if i % 100 == 0:\n",
    "        print(i, f'{loss.numpy()}, {w. numpy()}, {b.numpy()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
