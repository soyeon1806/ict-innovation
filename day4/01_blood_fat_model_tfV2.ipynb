{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"data\", \"Blood_fat.csv\")\n",
    "data = np.loadtxt(data_path, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([x_row1[0] for x_row1 in data], dtype = np.float64)\n",
    "x2 = np.array([x_row2[1] for x_row2 in data], dtype = np.float64)\n",
    "y_data = np.array([y_row[2] for y_row in data], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.Variable(tf.random.uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "a2 = tf.Variable(tf.random.uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random.uniform([1], 0, 100, dtype = tf.float64, seed = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(a1, a2, b):\n",
    "    return x1 * a1 + x2 * a2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(a1, a2, b):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(a1, a2, b) - y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 196.44899178861934, [5.44794858], [0.69916087], [81.15021325]\n",
      "100 73.34562237274673, [3.17218848], [0.32806259], [81.12240066]\n",
      "200 65.86955476544112, [2.74212659], [1.07757219], [81.12101247]\n",
      "300 59.36622930569443, [2.34187709], [1.77684157], [81.11970569]\n",
      "400 53.9871079865865, [1.97802284], [2.4125262], [81.11848993]\n",
      "500 49.80395616984404, [1.6573492], [2.97277141], [81.11738541]\n",
      "600 46.76463704741513, [1.3842076], [3.44997488], [81.11640649]\n",
      "700 44.697606160650224, [1.15911883], [3.8432267], [81.11555724]\n",
      "800 43.36891177152679, [0.97876994], [4.15831476], [81.11483084]\n",
      "900 42.55055147783667, [0.83730149], [4.4054759], [81.11421266]\n",
      "1000 42.06112742743825, [0.72793553], [4.59655165], [81.11368479]\n",
      "1100 41.77390541627687, [0.64417252], [4.74289715], [81.11322956]\n",
      "1200 41.60728934276381, [0.58038425], [4.85434532], [81.11283135]\n",
      "1300 41.511300890889565, [0.53197232], [4.93892988], [81.11247726]\n",
      "1400 41.456224163043686, [0.49530328], [5.00299873], [81.11215697]\n",
      "1500 41.42469566879676, [0.46756081], [5.0514722], [81.11186245]\n",
      "1600 41.406671459528, [0.44658589], [5.08812225], [81.11158753]\n",
      "1700 41.39637523876093, [0.43073379], [5.11582236], [81.11132745]\n",
      "1800 41.39049609528405, [0.41875607], [5.13675363], [81.11107862]\n",
      "1900 41.387139865725494, [0.40970708], [5.15256819], [81.11083831]\n",
      "2000 41.38522408489779, [0.40287132], [5.16451607], [81.11060444]\n",
      "2100 41.38413053709379, [0.39770784], [5.17354236], [81.11037545]\n",
      "2200 41.38350627349037, [0.39380776], [5.18036138], [81.11015014]\n",
      "2300 41.3831498310826, [0.39086214], [5.18551289], [81.10992762]\n",
      "2400 41.382946228210685, [0.38863757], [5.18940469], [81.10970721]\n",
      "2500 41.38282984534242, [0.38695768], [5.19234486], [81.1094884]\n",
      "2600 41.38276323510956, [0.38568927], [5.19456616], [81.1092708]\n",
      "2700 41.38272502772863, [0.38473169], [5.19624442], [81.10905412]\n",
      "2800 41.38270302842992, [0.38400892], [5.19751244], [81.10883814]\n",
      "2900 41.38269027825827, [0.38346353], [5.19847057], [81.10862269]\n",
      "3000 41.38268280609618, [0.38305213], [5.19919461], [81.10840765]\n",
      "3100 41.38267834583654, [0.38274195], [5.19974181], [81.10819291]\n",
      "3200 41.38267560433333, [0.38250823], [5.20015543], [81.10797841]\n",
      "3300 41.38267384365788, [0.38233227], [5.20046813], [81.1077641]\n",
      "3400 41.3826726427143, [0.38219995], [5.2007046], [81.10754992]\n",
      "3500 41.38267176120604, [0.38210058], [5.20088349], [81.10733586]\n",
      "3600 41.38267106200896, [0.38202611], [5.20101888], [81.10712188]\n",
      "3700 41.38267046687374, [0.38197046], [5.2011214], [81.10690798]\n",
      "3800 41.38266993114779, [0.38192901], [5.20119911], [81.10669412]\n",
      "3900 41.3826694293503, [0.38189829], [5.20125806], [81.10648032]\n",
      "4000 41.382668946940754, [0.38187568], [5.20130284], [81.10626655]\n",
      "4100 41.38266847562165, [0.3818592], [5.20133693], [81.10605282]\n",
      "4200 41.38266801065809, [0.38184734], [5.20136293], [81.10583911]\n",
      "4300 41.38266754934808, [0.38183898], [5.20138283], [81.10562543]\n",
      "4400 41.3826670901498, [0.38183326], [5.20139811], [81.10541177]\n",
      "4500 41.38266663218332, [0.38182953], [5.20140991], [81.10519813]\n",
      "4600 41.38266617494659, [0.38182731], [5.20141907], [81.10498451]\n",
      "4700 41.38266571815309, [0.38182622], [5.20142625], [81.1047709]\n",
      "4800 41.382665261639296, [0.381826], [5.20143192], [81.10455732]\n",
      "4900 41.382664805311904, [0.38182643], [5.20143647], [81.10434375]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost(a1, a2, b)\n",
    "    gradients = tape.gradient(loss, [a1, a2, b])\n",
    "    opt.apply_gradients(zip(gradients, [a1, a2, b]))\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i, f'{loss.numpy()}, {a1. numpy()}, {a2. numpy()}, {b.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[352.44387336]\n",
      "[213.00632974]\n",
      "[376.39779478]\n",
      "[263.8752489]\n",
      "[406.60509599]\n",
      "[237.48622099]\n",
      "[250.79957736]\n",
      "[295.84754425]\n",
      "[407.75057798]\n",
      "[338.60454716]\n",
      "[216.24803301]\n",
      "[276.33140829]\n",
      "[376.39779478]\n",
      "[222.5014128]\n",
      "[415.71835172]\n",
      "[357.11934364]\n",
      "[280.86273606]\n",
      "[376.54193729]\n",
      "[369.81318785]\n",
      "[289.26293732]\n",
      "[342.89819011]\n",
      "[226.3196861]\n",
      "[306.01273966]\n",
      "[310.1622401]\n",
      "[261.20245759]\n"
     ]
    }
   ],
   "source": [
    "da1 = a1.numpy()\n",
    "da2 = a2.numpy()\n",
    "db = b.numpy()\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    print((da1 * x1[i]) + (da2 * x2[i]) + db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
