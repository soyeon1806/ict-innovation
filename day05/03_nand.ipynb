{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype = np.float32)\n",
    "y_data = np.array([[1], [1], [1], [0]], dtype = np.float32)\n",
    "X = tf.placeholder(tf.float32, [None, 2], name = 'x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name = 'y-input')\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  0.9623219 w =  [[ 0.36583456]\n",
      " [-0.91746765]] b =  [-0.60242355]\n",
      "step =  100 cost =  0.7890414 w =  [[ 0.41627273]\n",
      " [-0.798044  ]] b =  [-0.20828246]\n",
      "step =  200 cost =  0.69167626 w =  [[ 0.41757533]\n",
      " [-0.7260651 ]] b =  [0.09420715]\n",
      "step =  300 cost =  0.63400936 w =  [[ 0.38553366]\n",
      " [-0.6906038 ]] b =  [0.32882577]\n",
      "step =  400 cost =  0.59599376 w =  [[ 0.33252147]\n",
      " [-0.6808197 ]] b =  [0.51578885]\n",
      "step =  500 cost =  0.56788695 w =  [[ 0.26686946]\n",
      " [-0.68842834]] b =  [0.6696371]\n",
      "step =  600 cost =  0.5451005 w =  [[ 0.19396298]\n",
      " [-0.7076229 ]] b =  [0.80029595]\n",
      "step =  700 cost =  0.5254498 w =  [[ 0.11727405]\n",
      " [-0.73443764]] b =  [0.9144755]\n",
      "step =  800 cost =  0.5078614 w =  [[ 0.03905465]\n",
      " [-0.7661793 ]] b =  [1.016735]\n",
      "step =  900 cost =  0.49178112 w =  [[-0.03923111]\n",
      " [-0.8010168 ]] b =  [1.1102017]\n",
      "step =  1000 cost =  0.47690207 w =  [[-0.11663749]\n",
      " [-0.8377069 ]] b =  [1.1970394]\n",
      "step =  1100 cost =  0.4630381 w =  [[-0.19256514]\n",
      " [-0.8754063 ]] b =  [1.2787595]\n",
      "step =  1200 cost =  0.45006356 w =  [[-0.26664823]\n",
      " [-0.9135469 ]] b =  [1.356427]\n",
      "step =  1300 cost =  0.43788505 w =  [[-0.3386793]\n",
      " [-0.9517486]] b =  [1.4308004]\n",
      "step =  1400 cost =  0.4264276 w =  [[-0.4085584 ]\n",
      " [-0.98976225]] b =  [1.5024252]\n",
      "step =  1500 cost =  0.41562796 w =  [[-0.4762567]\n",
      " [-1.0274267]] b =  [1.5716978]\n",
      "step =  1600 cost =  0.4054307 w =  [[-0.5417933]\n",
      " [-1.0646427]] b =  [1.6389133]\n",
      "step =  1700 cost =  0.3957867 w =  [[-0.6052177]\n",
      " [-1.1013513]] b =  [1.7042935]\n",
      "step =  1800 cost =  0.3866518 w =  [[-0.666598 ]\n",
      " [-1.1375215]] b =  [1.7680091]\n",
      "step =  1900 cost =  0.3779863 w =  [[-0.7260139]\n",
      " [-1.1731416]] b =  [1.830195]\n",
      "step =  2000 cost =  0.36975423 w =  [[-0.7835505]\n",
      " [-1.2082108]] b =  [1.8909597]\n",
      "step =  2100 cost =  0.36192292 w =  [[-0.83929473]\n",
      " [-1.2427366 ]] b =  [1.9503939]\n",
      "step =  2200 cost =  0.35446286 w =  [[-0.89333236]\n",
      " [-1.2767313 ]] b =  [2.0085733]\n",
      "step =  2300 cost =  0.34734714 w =  [[-0.94574845]\n",
      " [-1.3102092 ]] b =  [2.0655644]\n",
      "step =  2400 cost =  0.34055132 w =  [[-0.99662423]\n",
      " [-1.3431864 ]] b =  [2.1214259]\n",
      "step =  2500 cost =  0.3340532 w =  [[-1.0460373]\n",
      " [-1.3756794]] b =  [2.1762085]\n",
      "step =  2600 cost =  0.32783225 w =  [[-1.0940617]\n",
      " [-1.4077048]] b =  [2.2299607]\n",
      "step =  2700 cost =  0.32187012 w =  [[-1.1407678]\n",
      " [-1.4392784]] b =  [2.282726]\n",
      "step =  2800 cost =  0.3161498 w =  [[-1.1862224]\n",
      " [-1.4704158]] b =  [2.3345437]\n",
      "step =  2900 cost =  0.3106558 w =  [[-1.2304863]\n",
      " [-1.5011315]] b =  [2.3854523]\n",
      "step =  3000 cost =  0.30537397 w =  [[-1.2736179]\n",
      " [-1.5314387]] b =  [2.4354854]\n",
      "step =  3100 cost =  0.30029112 w =  [[-1.3156729]\n",
      " [-1.5613519]] b =  [2.484676]\n",
      "step =  3200 cost =  0.29539537 w =  [[-1.356703 ]\n",
      " [-1.5908823]] b =  [2.533055]\n",
      "step =  3300 cost =  0.2906757 w =  [[-1.3967569]\n",
      " [-1.6200416]] b =  [2.5806513]\n",
      "step =  3400 cost =  0.2861218 w =  [[-1.43588  ]\n",
      " [-1.6488408]] b =  [2.627493]\n",
      "step =  3500 cost =  0.2817243 w =  [[-1.4741157]\n",
      " [-1.6772904]] b =  [2.6736052]\n",
      "step =  3600 cost =  0.27747464 w =  [[-1.5115043]\n",
      " [-1.7053999]] b =  [2.7190132]\n",
      "step =  3700 cost =  0.2733648 w =  [[-1.5480832]\n",
      " [-1.7331784]] b =  [2.76374]\n",
      "step =  3800 cost =  0.2693872 w =  [[-1.5838885]\n",
      " [-1.7606343]] b =  [2.8078077]\n",
      "step =  3900 cost =  0.26553503 w =  [[-1.6189537]\n",
      " [-1.7877759]] b =  [2.8512373]\n",
      "step =  4000 cost =  0.26180196 w =  [[-1.6533102]\n",
      " [-1.8146111]] b =  [2.8940487]\n",
      "step =  4100 cost =  0.25818184 w =  [[-1.6869882]\n",
      " [-1.8411471]] b =  [2.936262]\n",
      "step =  4200 cost =  0.25466925 w =  [[-1.7200154]\n",
      " [-1.8673908]] b =  [2.9778943]\n",
      "step =  4300 cost =  0.25125897 w =  [[-1.7524188]\n",
      " [-1.8933488]] b =  [3.018963]\n",
      "step =  4400 cost =  0.24794617 w =  [[-1.7842225]\n",
      " [-1.9190277]] b =  [3.059486]\n",
      "step =  4500 cost =  0.24472627 w =  [[-1.815451 ]\n",
      " [-1.9444335]] b =  [3.099478]\n",
      "step =  4600 cost =  0.24159522 w =  [[-1.8461266]\n",
      " [-1.9695721]] b =  [3.1389537]\n",
      "step =  4700 cost =  0.23854885 w =  [[-1.8762702]\n",
      " [-1.9944489]] b =  [3.1779287]\n",
      "step =  4800 cost =  0.23558357 w =  [[-1.9059017]\n",
      " [-2.0190694]] b =  [3.2164166]\n",
      "step =  4900 cost =  0.23269574 w =  [[-1.9350404]\n",
      " [-2.0434384]] b =  [3.2544296]\n",
      "step =  5000 cost =  0.22988224 w =  [[-1.9637038]\n",
      " [-2.0675614]] b =  [3.2919815]\n",
      "step =  5100 cost =  0.22713998 w =  [[-1.9919089]\n",
      " [-2.0914438]] b =  [3.3290834]\n",
      "step =  5200 cost =  0.2244659 w =  [[-2.0196722]\n",
      " [-2.1150885]] b =  [3.3657482]\n",
      "step =  5300 cost =  0.22185744 w =  [[-2.0470085]\n",
      " [-2.138501 ]] b =  [3.401986]\n",
      "step =  5400 cost =  0.21931192 w =  [[-2.0739324]\n",
      " [-2.1616857]] b =  [3.437808]\n",
      "step =  5500 cost =  0.21682689 w =  [[-2.1004581]\n",
      " [-2.1846466]] b =  [3.473225]\n",
      "step =  5600 cost =  0.21440002 w =  [[-2.126599]\n",
      " [-2.207388]] b =  [3.5082462]\n",
      "step =  5700 cost =  0.21202916 w =  [[-2.1523669]\n",
      " [-2.2299135]] b =  [3.542881]\n",
      "step =  5800 cost =  0.20971227 w =  [[-2.1777742]\n",
      " [-2.252227 ]] b =  [3.5771387]\n",
      "step =  5900 cost =  0.20744735 w =  [[-2.2028315]\n",
      " [-2.2743318]] b =  [3.6110282]\n",
      "step =  6000 cost =  0.20523258 w =  [[-2.2275507]\n",
      " [-2.2962325]] b =  [3.644558]\n",
      "step =  6100 cost =  0.20306602 w =  [[-2.2519417]\n",
      " [-2.3179324]] b =  [3.6777365]\n",
      "step =  6200 cost =  0.20094617 w =  [[-2.2760139]\n",
      " [-2.3394344]] b =  [3.7105718]\n",
      "step =  6300 cost =  0.19887136 w =  [[-2.2997775]\n",
      " [-2.360742 ]] b =  [3.7430706]\n",
      "step =  6400 cost =  0.19684005 w =  [[-2.323241 ]\n",
      " [-2.3818586]] b =  [3.7752411]\n",
      "step =  6500 cost =  0.19485088 w =  [[-2.3464131]\n",
      " [-2.4027872]] b =  [3.8070893]\n",
      "step =  6600 cost =  0.19290239 w =  [[-2.3693016]\n",
      " [-2.4235308]] b =  [3.8386233]\n",
      "step =  6700 cost =  0.19099328 w =  [[-2.3919148]\n",
      " [-2.4440932]] b =  [3.8698492]\n",
      "step =  6800 cost =  0.18912227 w =  [[-2.4142604]\n",
      " [-2.4644763]] b =  [3.9007723]\n",
      "step =  6900 cost =  0.18728812 w =  [[-2.436345 ]\n",
      " [-2.4846838]] b =  [3.931401]\n",
      "step =  7000 cost =  0.1854898 w =  [[-2.458176]\n",
      " [-2.504718]] b =  [3.96174]\n",
      "step =  7100 cost =  0.18372619 w =  [[-2.4797595]\n",
      " [-2.524582 ]] b =  [3.9917946]\n",
      "step =  7200 cost =  0.18199614 w =  [[-2.5011027]\n",
      " [-2.5442781]] b =  [4.0215716]\n",
      "step =  7300 cost =  0.18029867 w =  [[-2.5222113]\n",
      " [-2.563809 ]] b =  [4.051075]\n",
      "step =  7400 cost =  0.17863294 w =  [[-2.54309  ]\n",
      " [-2.5831773]] b =  [4.080311]\n",
      "step =  7500 cost =  0.1769979 w =  [[-2.5637462]\n",
      " [-2.6023855]] b =  [4.1092844]\n",
      "step =  7600 cost =  0.17539263 w =  [[-2.5841844]\n",
      " [-2.6214364]] b =  [4.1380014]\n",
      "step =  7700 cost =  0.17381641 w =  [[-2.6044102]\n",
      " [-2.640332 ]] b =  [4.1664643]\n",
      "step =  7800 cost =  0.17226835 w =  [[-2.6244285]\n",
      " [-2.6590745]] b =  [4.1946797]\n",
      "step =  7900 cost =  0.1707477 w =  [[-2.6442435]\n",
      " [-2.677667 ]] b =  [4.2226515]\n",
      "step =  8000 cost =  0.16925362 w =  [[-2.6638606]\n",
      " [-2.696111 ]] b =  [4.2503843]\n",
      "step =  8100 cost =  0.16778547 w =  [[-2.6832843]\n",
      " [-2.7144084]] b =  [4.2778826]\n",
      "step =  8200 cost =  0.16634251 w =  [[-2.7025185]\n",
      " [-2.7325618]] b =  [4.3051505]\n",
      "step =  8300 cost =  0.16492413 w =  [[-2.7215672]\n",
      " [-2.7505734]] b =  [4.33219]\n",
      "step =  8400 cost =  0.16352963 w =  [[-2.7404354]\n",
      " [-2.7684448]] b =  [4.359007]\n",
      "step =  8500 cost =  0.16215831 w =  [[-2.7591257]\n",
      " [-2.7861784]] b =  [4.385607]\n",
      "step =  8600 cost =  0.1608098 w =  [[-2.7776425]\n",
      " [-2.8037767]] b =  [4.4119883]\n",
      "step =  8700 cost =  0.1594833 w =  [[-2.7959893]\n",
      " [-2.821241 ]] b =  [4.4381595]\n",
      "step =  8800 cost =  0.15817837 w =  [[-2.81417 ]\n",
      " [-2.838573]] b =  [4.4641213]\n",
      "step =  8900 cost =  0.15689446 w =  [[-2.8321874]\n",
      " [-2.8557749]] b =  [4.489878]\n",
      "step =  9000 cost =  0.15563098 w =  [[-2.8500445]\n",
      " [-2.8728487]] b =  [4.5154347]\n",
      "step =  9100 cost =  0.15438747 w =  [[-2.8677454]\n",
      " [-2.8897955]] b =  [4.540793]\n",
      "step =  9200 cost =  0.15316345 w =  [[-2.8852928]\n",
      " [-2.9066176]] b =  [4.565956]\n",
      "step =  9300 cost =  0.15195842 w =  [[-2.90269  ]\n",
      " [-2.9233167]] b =  [4.590926]\n",
      "step =  9400 cost =  0.15077202 w =  [[-2.9199386]\n",
      " [-2.9398944]] b =  [4.615708]\n",
      "step =  9500 cost =  0.14960371 w =  [[-2.9370422]\n",
      " [-2.9563525]] b =  [4.640303]\n",
      "step =  9600 cost =  0.14845316 w =  [[-2.9540036]\n",
      " [-2.9726923]] b =  [4.6647153]\n",
      "step =  9700 cost =  0.14731982 w =  [[-2.9708252]\n",
      " [-2.9889154]] b =  [4.6889477]\n",
      "step =  9800 cost =  0.1462034 w =  [[-2.9875095]\n",
      " [-3.0050242]] b =  [4.7130013]\n",
      "step =  9900 cost =  0.14510351 w =  [[-3.0040596]\n",
      " [-3.0210197]] b =  [4.736879]\n",
      "step =  10000 cost =  0.14401975 w =  [[-3.020477 ]\n",
      " [-3.0369022]] b =  [4.7605853]\n",
      "\n",
      "Hypothesis:  [[0.9915121 ]\n",
      " [0.84860265]\n",
      " [0.85070086]\n",
      " [0.21470508]] \n",
      "Correct:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n",
      "\n",
      "새로운 데이터 Hypothesis:  [[0.21470508]\n",
      " [0.84860265]\n",
      " [0.85070086]\n",
      " [0.9915121 ]] \n",
      "새로운 데이터 Prediction:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step = \", step, \"cost = \", sess.run(cost, feed_dict = {X: x_data, Y: y_data}), \"w = \", sess.run(W), \"b = \", sess.run(b))\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "    new_data = np.array([[1, 1], [0, 1], [1, 0], [0, 0]], dtype = np.float32)\n",
    "    new_prediction = sess.run(predicted, feed_dict = {X: new_data})\n",
    "    new_hypothesis = sess.run(hypothesis, feed_dict = {X: new_data})\n",
    "    print(\"\\n새로운 데이터 Hypothesis: \", new_hypothesis, \"\\n새로운 데이터 Prediction: \", new_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
